{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfXaxIs7mkObPYZbb35tbM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usaidahmed01/Deep-Learning/blob/master/20Jan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train.shape\n",
        "x_test.shape\n",
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "    'dog','frog','horse','ship','truck']\n",
        "plt.figure(figsize=(6,6))\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.imshow(x_train[i])\n",
        "  plt.title(class_names[y_train[i][0]])\n",
        "  plt.axis('off')\n",
        "plt.show()\n",
        "#Normalization\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D(2,2),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "history = model.fit(\n",
        "    x_train, y_train, epochs=10, validation_data=(x_test, y_test)\n",
        ")\n",
        "# layers.Conv2D(128, (3,3), activation='relu'),\n",
        "# layers.MaxPooling2D(2,2),\n",
        "\n",
        "# layers.Conv2D(32, (5,5), activation='relu')\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "predictions\n",
        "\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "y_true = y_test.flatten()\n",
        "wrong_indices = np.where(y_pred != y_true)[0]\n",
        "print('Total wrong predictions', len(wrong_indices))\n",
        "plt.figure(figsize=(8,8))\n",
        "for i, idx in enumerate(wrong_indices[:9]):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.imshow(x_test[idx])\n",
        "  plt.title(\n",
        "      f'Pred: {class_names[y_pred[idx]]}\\n'\n",
        "      f'True: {class_names[y_true[idx]]}'\n",
        "  )\n",
        "  plt.axis('off')\n",
        "plt.show()\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm, xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "#Data Augmentation\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(x_train)\n",
        "history_aug = model.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=64),\n",
        "    epochs=10,\n",
        "    validation_data=(x_test, y_test)\n",
        ")\n",
        "predictions = model.predict(x_test)\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "y_true = y_test.flatten()\n",
        "wrong_indices = np.where(y_pred != y_true)[0]\n",
        "print('Total wrong predictions', len(wrong_indices))\n",
        "#TRANSFER LEARNING\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(32,32,3)\n",
        ")\n",
        "base_model.trainable=False\n",
        "transfer_model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "CiB4_tKr9rrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6H6YwIvY8ICC"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(model.predict(x_test) , axis = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = y_test.flatten()\n"
      ],
      "metadata": {
        "id": "7TdRSSUq8Q-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_indices = np.where(y_true != y_true)[0]\n",
        "print('Total wrong predictions ', len(wrong_indices))"
      ],
      "metadata": {
        "id": "jQmg1YfJ8TdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (8 , 8))\n",
        "for i, idx in enumerate(wrong_indices[:9]):\n",
        "  plt.subplot(3 , 3 , i + 1)\n",
        "  plt.imshow(x_test[idx])\n",
        "  plt.title(f'Pred:{class_names[y_pred[idx]]} \\n'\n",
        "  f'True: {class_names[y_true[idx]]}')\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "-odOkawP8Vrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_pred , y_true)\n",
        "\n",
        "plt.figure(figsize = (10 , 8))\n",
        "sns.heatmap(cm, xticklabels = class_names, yticklabels = class_names ,cmap = 'Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')"
      ],
      "metadata": {
        "id": "RN96_cOF8YUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "  # means model is good but the data is unstructured\n",
        "\n",
        "  datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rotation_range = 15, # camera angle\n",
        "      width_shift_range = 0.1, # camera movement\n",
        "      height_shift_range = 0.1,\n",
        "      horizontal_flip = True, # Mirror image\n",
        "      # vertical_flip = True\n",
        "      # zoom_range = 0.1,\n",
        "  )"
      ],
      "metadata": {
        "id": "s6B8ZmXS9vZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen.fit(x_train)\n",
        "history_aug = model.fit(\n",
        "    datagen.flow(x_train , y_train , batch_size = 64),\n",
        "    epochs = 10,\n",
        "    validation_data = (x_test , y_test)\n",
        ")"
      ],
      "metadata": {
        "id": "k8ZJkSL2_X3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)\n",
        "y_pred = np.argmax(predictions , axis = 1)\n",
        "y_true = y_test.flatten()\n",
        "wrong_indices = np.where(y_true != y_pred)[0]\n",
        "print('Total wrong predictions ', len(wrong_indices))"
      ],
      "metadata": {
        "id": "WWntrmyNDeF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer Learning: This technique reuses a pre-trained model on a new, related task.\n",
        "# It leverages knowledge gained from a large dataset (like ImageNet) to solve a new problem,\n",
        "# especially when the new dataset is small.\n",
        "\n",
        "# Load a pre-trained MobileNetV2 model.\n",
        "# MobileNetV2 is a lightweight deep convolutional neural network architecture.\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    weights='imagenet', # Use weights pre-trained on the ImageNet dataset.\n",
        "    include_top=False,  # Exclude the classifier (the top layers) from the original model.\n",
        "                        # This allows us to add our own classification layers for the new task.\n",
        "    input_shape=(32,32,3) # Define the input shape for our specific dataset (CIFAR-10 images are 32x32x3).\n",
        ")\n",
        "\n",
        "# Freeze the weights of the base model.\n",
        "# This prevents the pre-trained weights from being updated during the training of our new layers.\n",
        "# This is common in the initial stages of transfer learning to use the base model as a fixed feature extractor.\n",
        "base_model.trainable=False\n",
        "\n",
        "# Create a new sequential model on top of the pre-trained base model.\n",
        "transfer_model = tf.keras.Sequential([\n",
        "    base_model, # The frozen MobileNetV2 model acts as a feature extractor.\n",
        "    layers.GlobalAveragePooling2D(), # A layer to reduce the spatial dimensions of the feature maps\n",
        "                                     # to a single vector per feature map, effectively flattening them.\n",
        "                                     # This is suitable for replacing the dense layers at the top.\n",
        "    layers.Dense(128, activation='relu'), # A new fully connected hidden layer with ReLU activation.\n",
        "    layers.Dense(10, activation='softmax') # The output layer with 10 units (for 10 CIFAR-10 classes)\n",
        "                                         # and softmax activation for multi-class classification.\n",
        "])\n",
        "\n",
        "# When to use these built-in models (Transfer Learning):\n",
        "# 1. When you have a small dataset but a similar task has a large dataset available (e.g., ImageNet).\n",
        "# 2. To leverage powerful, pre-trained feature extractors, saving time and computational resources.\n",
        "# 3. To achieve good performance with limited training data.\n",
        "# 4. As a strong starting point for fine-tuning (where you might later unfreeze some layers of the base model).\n",
        "# 5. When the problem domain is similar to the domain the model was originally trained on."
      ],
      "metadata": {
        "id": "TEgnmRT6E8Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# agar pixels bht hi chotay ahin tou best hai ke maxpooling apply and if pixels barhay hain like 264 x 264 so we can use average pooling and all"
      ],
      "metadata": {
        "id": "I3Ps05CzGIY9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
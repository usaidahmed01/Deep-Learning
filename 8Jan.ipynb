{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyGUKQm8fy1xqrnLFbToch",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usaidahmed01/Deep-Learning/blob/master/8Jan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp5WcCYbII-C"
      },
      "outputs": [],
      "source": [
        "# Computer Vision\n",
        "\n",
        "Computer vision means teaching computers to see and understand images the way humans do.\n",
        "\n",
        "We dont see pixels instead we see edges -> patterns -> objects\n",
        "\n",
        "Computer Vision tasks:\n",
        "  - Image Classification (What is in the image)\n",
        "  - Object Detection (Where is the object)\n",
        "  - Image Segmentation (Which pixel belongs to what)\n",
        "\n",
        "\n",
        "ML failed on CV because of the size of images.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "What is CNN (Convolutional Neural Network)\n",
        "A CNN is neural network specially designed for image classification.\n",
        "  Instead of connecting every pixel to every neuron, look at small regions at a time. This small region is looked through a window and that sliding window is called a filter(Kernel)\n",
        "\n",
        "Convolution produces feature Map"
      ],
      "metadata": {
        "id": "bPmVCHukN-N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "What filter learns:\n",
        "  - Early layers -> edges, corners\n",
        "  - Middle layers -> textures, patterns\n",
        "  - Deep layers -> objects(eyes, wheels, faces)"
      ],
      "metadata": {
        "id": "daDoajaOQdAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Computer vision means teaching  computers to see and understand images the way humans do.\n",
        "You donâ€™t see pixels\n",
        "You see edges -> shapes -> patterns -> objects\n",
        "Computer vision tasks:\n",
        "-\tImage classification (What is in the image)\n",
        "-\tObject detection (Where is the object)\n",
        "-\tImage segmentation (which pixel belongs to what)\n",
        "\n",
        "What is CNN (Convolutional Neural network)\n",
        "A CNN is a neural network specially designed for images\n",
        "Instead of connecting every pixel to every neuron, look at small regions at a time\n",
        "This small region is looked through a window\n",
        "That sliding window is called a filter ( kernel)\n",
        "Convolution produces a feature map\n",
        "\n",
        "What filter learns:\n",
        "-\tEarly layers -> edges, corners\n",
        "-\tMiddle layers -> textures, patterns\n",
        "-\tDeep layers -> objects (eyes, wheels, faces\n",
        "Convolution layer:\n",
        "Learns filter automatically\n",
        "Extract features\n",
        "\n",
        "ReLU Activation\n",
        "Introduces non-linearilty\n",
        "Speeds  up training\n",
        "Ignores negative values\n",
        "Keeps strong signals\n",
        "\n",
        "Pooling Layer:\n",
        "Purpose: Downsample the image\n",
        "-\tMaxpooling keeps the strongest signal\n",
        "-\tReduces size\n",
        "-\tAdds robustness\n",
        "After multiple conv + pool layers:\n",
        "Image becomes small but information rich\n",
        "Thenk:\n",
        "Flatten\n",
        "Dense layers\n",
        "Output probabilities\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "wfzwA_ZUSjyT",
        "outputId": "d2911432-0973-4fae-a469-f2a35bd3b192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-213155884.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-213155884.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Cooling Layer:\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Computer Vision\n",
        "Computer vision is like teaching computers to 'see' and understand images the way humans do. We don't just see individual dots (pixels); our brains recognize edges, then combine them into patterns, and finally identify objects. Computer vision aims to enable machines to do the same.\n",
        "\n",
        "Common Computer Vision tasks:\n",
        "\n",
        "Image Classification: Answering \"What is in this image?\" (e.g., Is it a dog or a cat?)\n",
        "Object Detection: Answering \"Where is the object in this image?\" (e.g., Drawing a box around a car in a photo.)\n",
        "Image Segmentation: Answering \"Which pixel belongs to what?\" (e.g., Highlighting every pixel that belongs to a person in an image.)\n",
        "What is a CNN (Convolutional Neural Network)?\n",
        "A CNN is a special kind of neural network that's really good at working with images. Instead of looking at every single pixel individually, which would be too much for a large image, a CNN looks at small areas of the image at a time. It uses a 'sliding window' called a filter (or kernel) to scan over the image. This process of sliding the filter and performing calculations is called convolution, and it produces a feature map that highlights certain patterns.\n",
        "\n",
        "What Filters Learn:\n",
        "Filters in a CNN learn to recognize different things in an image:\n",
        "\n",
        "Early layers: These filters learn very basic things like edges (where colors change sharply) and corners.\n",
        "Middle layers: Filters here combine those basic edges and corners to recognize more complex textures and patterns (like patterns of fur or brick).\n",
        "Deep layers: Filters at deeper levels learn to identify even more complex parts of objects, like eyes, wheels, or faces.\n",
        "Other Important Parts of a CNN:\n",
        "Convolution Layer: This is where the CNN automatically learns the best filters to extract important features from the image.\n",
        "ReLU Activation: This layer introduces non-linearity, which means it helps the network learn more complex relationships. It also speeds up training and makes sure that only strong, positive signals are passed forward.\n",
        "Pooling Layer (like Maxpooling): The main goal of this layer is to make the image smaller (downsample it) while keeping the most important information. Maxpooling specifically takes the strongest signal from a small area. This reduces the size of the data and helps the network be more robust, meaning it's less sensitive to small shifts or changes in the image.\n",
        "After multiple layers of convolution and pooling, the image becomes much smaller but is full of rich, important information. This information then goes through:\n",
        "\n",
        "Flatten: This step converts the processed image data into a single long list of numbers.\n",
        "Dense layers: These are standard neural network layers that use this list of numbers to make a final decision.\n",
        "Output probabilities: The final result is usually a set of probabilities, telling you how likely it is that the image contains certain objects (e.g., 90% cat, 10% dog)."
      ],
      "metadata": {
        "id": "sJqj7sajSmUF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}